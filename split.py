#!/usr/bin/env python

# ==============================================================================
# Copyright 2017 Robert Cottrell. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

from sklearn.model_selection import train_test_split

# The number of training samples to hold out for validation.
VALIDATION_SIZE = 3200

# Seed used for sampling validation examples.
RANDOM_STATE=1

def load_mappings(data_set):
    mappings = []
    with open(data_set + '/mappings.csv') as file:
        file.readline()
        for line in file:
            name, label = line.strip().split(',')
            mapping = [
                data_set + '/processed-' + name,
                str(min(6, len(label))),
                label[0] if len(label) > 0 else '0',
                label[1] if len(label) > 1 else '0',
                label[2] if len(label) > 2 else '0',
                label[3] if len(label) > 3 else '0',
                label[4] if len(label) > 4 else '0'
            ]
            mappings.append(mapping)
    return mappings
    
def save_data(data_set, mappings):
    with open(data_set + '.csv', 'w') as file:
        for mapping in mappings:
            file.write(','.join(mapping) + '\n')

def split_validation(mappings):
    counts = [min(int(x[1]), 5) for x in mappings]
    train_mappings, validation_mappings, _, _ = train_test_split(
        mappings, counts, test_size=VALIDATION_SIZE, random_state=RANDOM_STATE, stratify=counts)
    return train_mappings, validation_mappings

def main():
    # Read in mapping files generated by preprocess.py.
    train_mappings = load_mappings('train')
    extra_mappings = load_mappings('extra')
    test_mappings = load_mappings('test')
    
    # Split out validation set from the training set and append additional
    # training exmaples.
    train_mappings, validation_mappings = split_validation(train_mappings)
    train_mappings.extend(extra_mappings)
    
    # Split the training set into separate sets for each digit.
    train1_mappings = filter(lambda x: x[1] == '1', train_mappings)
    train2_mappings = filter(lambda x: x[1] == '2', train_mappings)
    train3_mappings = filter(lambda x: x[1] == '3', train_mappings)
    train4_mappings = filter(lambda x: x[1] == '4', train_mappings)
    train5_mappings = filter(lambda x: x[1] == '5' or x[1] == '6', train_mappings)
    
    # Save the data sets.
    save_data('train-1', train1_mappings)
    save_data('train-2', train2_mappings)
    save_data('train-3', train3_mappings)
    save_data('train-4', train4_mappings)
    save_data('train-5', train5_mappings)
    save_data('train', train_mappings)
    save_data('validation', validation_mappings)
    save_data('test', test_mappings)

if __name__ == '__main__':
    main()
